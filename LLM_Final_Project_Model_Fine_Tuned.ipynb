{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "An53lin92uAz"
      },
      "outputs": [],
      "source": [
        "!pip -q install transformers datasets evaluate rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "from transformers import AutoTokenizer, EarlyStoppingCallback\n",
        "\n",
        "t5_base = \"google-t5/t5-base\"\n",
        "data = load_dataset(\"abisee/cnn_dailymail\", \"3.0.0\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(t5_base)\n",
        "data"
      ],
      "metadata": {
        "id": "AoMSlP2vBZT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1263631-0bb1-4e7a-d971-211aff9cf853"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 287113\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 13368\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 11490\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_percent, val_percent, test_percent = 0.8, 0.1, 0.1\n",
        "\n",
        "\n",
        "def load_data_sampled(max_samples=10000):\n",
        "  train_df = pd.DataFrame(data['train'])\n",
        "  test_df = pd.DataFrame(data['test'])\n",
        "  val_df = pd.DataFrame(data['validation'])\n",
        "  train_df = train_df.sample(int(max_samples * train_percent)).reset_index(drop=True)\n",
        "  test_df = test_df.sample(int(max_samples * test_percent)).reset_index(drop=True)\n",
        "  val_df = val_df.sample(int(max_samples * val_percent)).reset_index(drop=True)\n",
        "  return train_df, test_df, val_df\n",
        "\n",
        "train_df, test_df, val_df = load_data_sampled(max_samples=10000)\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "\n",
        "sampled_data = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'test': test_dataset,\n",
        "    'validation': val_dataset\n",
        "})\n",
        "\n",
        "print(\"New DatasetDict rows and features below:\\n\")\n",
        "sampled_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikSGT14CKllA",
        "outputId": "b9c3ccb6-36fe-4a12-e71f-168b0f28cdb8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New DatasetDict rows and features below:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 8000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"summarize: \"\n",
        "def preprocess_function(examples):\n",
        "    inputs = [prefix + str(article) for article in examples[\"article\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True, padding=True)\n",
        "\n",
        "    labels = tokenizer(examples[\"highlights\"], max_length=150, truncation=True, padding=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_data = sampled_data.map(preprocess_function, batched=True, remove_columns=sampled_data['train'].column_names)\n",
        "tokenized_data"
      ],
      "metadata": {
        "id": "HolisYWC9dMn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272,
          "referenced_widgets": [
            "34c4e47f8cec46f3910d980ff2d836d4",
            "8f3df05322314065ba68d8c591e1c8a9",
            "a3cfb42f8aa443f6965d2454ea9fe54d",
            "a9b9c55e2cde48c3bb22414154bd17a4",
            "71d3e729aec444c48bad2a2bccc38695",
            "a23d105bc1a147cf9c8aeb2c00863254",
            "60afab4d93de4f5a91870af6989ce547",
            "8c59d1646f5642e6a70768c507084be7",
            "e2854b982a0a47518da9073573042ad5",
            "1242d71792cd4a1f95a3e13436c97483",
            "b99c55a1cc8a43ae800a466b68acce2e",
            "12d63935cf854921b5273519bdf20ece",
            "6021673e178b490a8a7342368f694059",
            "44f616373a5145e2929f359596e0af15",
            "9c89da59e2024cd887f2f52a086c977e",
            "c27c6f9c553b46db9639341e418690f3",
            "fc6c0596d70a4857aef2ef527241a7c7",
            "44726141963a4872a161523922fd603e",
            "bd6a864a6b004b3191501c29797a564e",
            "5bbd75a52db847ea96388875db47ba4d",
            "e7f8174d1c2d4c8a8a10c38c924198cd",
            "a625b0c9c01d452c81515682cfb8f282",
            "6967ec01c25a4493bd70a090e61f7d6f",
            "8c351db1960744cb9f34bddde9d51aa8",
            "d6c7d42ff4af4c2688d1c2a028ae8f48",
            "b684104bb3b446c5823594f9d7dd70ab",
            "ef6891ffadf94d94aa2d76cd9e6f44b9",
            "b5a0549eb7284c98aa79dbfd512c09b1",
            "e92a164007e94519ae9bd521ae718f6a",
            "d7d9a88fb52c47b0a0caaa9b17b4aaac",
            "78239cc66ae2479e87d9b8759bea91ea",
            "f93c3343ef544ae484d78e2ac595d433",
            "5f8ad101950b4e9c89ca9ec11b3c5a73"
          ]
        },
        "outputId": "e6833ec9-0b7a-4b35-c3bc-eb9915e56e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34c4e47f8cec46f3910d980ff2d836d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12d63935cf854921b5273519bdf20ece"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6967ec01c25a4493bd70a090e61f7d6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 8000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "import evaluate\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=t5_base, label_pad_token_id=-100)\n",
        "rouge_metric = evaluate.load(\"rouge\")"
      ],
      "metadata": {
        "id": "jxUeL8pA-xKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "  predictions, labels = eval_preds\n",
        "  decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "  labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "  decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "  result = rouge_metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "  prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "  result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "  return {k: round(v, 4) for k, v in result.items()}"
      ],
      "metadata": {
        "id": "nzHll_Oy-y7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    t5_base,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        ")\n",
        "model.to(\"cuda\")\n",
        "\n",
        "model.gradient_checkpointing_enable(\n",
        "    gradient_checkpointing_kwargs={\"use_reentrant\": False}\n",
        ")\n",
        "model.zero_grad()"
      ],
      "metadata": {
        "id": "cvCn2SE7CVWB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "838dd398-4748-415c-cba0-8d9e6152ff50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Sap Yap\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_arguments = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"fine-tuned-t5-cnn-dailymail-10000\",\n",
        "    num_train_epochs=6,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=200,\n",
        "    logging_steps=100,\n",
        "    weight_decay=0.03,\n",
        "    learning_rate = 8e-5,\n",
        "    logging_dir='./logs',\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"rouge2\",\n",
        "    save_total_limit=3,\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=150,\n",
        "    generation_num_beams=5,\n",
        "    bf16=True,\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_arguments,\n",
        "    train_dataset=tokenized_data[\"train\"],\n",
        "    eval_dataset=tokenized_data[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "L9V_8b-o1rJ6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "cd850959-2090-44de-fe1b-2d84901626da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3000/3000 8:54:48, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.770800</td>\n",
              "      <td>0.830198</td>\n",
              "      <td>0.234700</td>\n",
              "      <td>0.107700</td>\n",
              "      <td>0.163300</td>\n",
              "      <td>0.163600</td>\n",
              "      <td>53.630000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.723600</td>\n",
              "      <td>0.823444</td>\n",
              "      <td>0.255100</td>\n",
              "      <td>0.118400</td>\n",
              "      <td>0.177100</td>\n",
              "      <td>0.177500</td>\n",
              "      <td>57.932000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.727000</td>\n",
              "      <td>0.822413</td>\n",
              "      <td>0.261700</td>\n",
              "      <td>0.120800</td>\n",
              "      <td>0.181900</td>\n",
              "      <td>0.182400</td>\n",
              "      <td>60.128000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.730100</td>\n",
              "      <td>0.821479</td>\n",
              "      <td>0.261400</td>\n",
              "      <td>0.120800</td>\n",
              "      <td>0.182100</td>\n",
              "      <td>0.182300</td>\n",
              "      <td>59.024000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.730800</td>\n",
              "      <td>0.821524</td>\n",
              "      <td>0.263800</td>\n",
              "      <td>0.122800</td>\n",
              "      <td>0.183500</td>\n",
              "      <td>0.183800</td>\n",
              "      <td>59.633000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.730400</td>\n",
              "      <td>0.821548</td>\n",
              "      <td>0.263900</td>\n",
              "      <td>0.122100</td>\n",
              "      <td>0.183500</td>\n",
              "      <td>0.183700</td>\n",
              "      <td>59.929000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
            "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3000, training_loss=1.0296797841389973, metrics={'train_runtime': 32091.2395, 'train_samples_per_second': 1.496, 'train_steps_per_second': 0.093, 'total_flos': 5.845995749376e+16, 'train_loss': 1.0296797841389973, 'epoch': 6.0})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = \"fine-tuned-t5-cnn-dailymail-model\"\n",
        "trainer.save_model(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vv1pEANmayn",
        "outputId": "1ab10807-44e6-4f3f-e785-8962cc8c05f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('fine-tuned-t5-cnn-dailymail-model\\\\tokenizer_config.json',\n",
              " 'fine-tuned-t5-cnn-dailymail-model\\\\special_tokens_map.json',\n",
              " 'fine-tuned-t5-cnn-dailymail-model\\\\tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the now fine-tuned model\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "model_path = \"ramyj/fine-tuned-t5-cnn-dailymail\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "xm5C8T24K-F6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "sample_articles = sampled_data[\"test\"][\"article\"][:1]\n",
        "sample_highlights = sampled_data[\"test\"][\"highlights\"][:1]\n",
        "prefix = \"summarize: \"\n",
        "\n",
        "\n",
        "for i, (article, reference) in enumerate(zip(sample_articles, sample_highlights)):\n",
        "    print(f\"Article {i+1}\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Prepare input for the model (single article)\n",
        "    input_text = prefix + article\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "    # Generate summary\n",
        "    output = model.generate(\n",
        "        **inputs,\n",
        "        max_length=150,\n",
        "        min_length=30,\n",
        "        num_beams=5,\n",
        "        length_penalty=1.0,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    # Decode the generated output\n",
        "    decoded_output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
        "\n",
        "    print(\"\\nGENERATED SUMMARY:\")\n",
        "    # Format the generated summary with line breaks every ~80 characters\n",
        "    formatted_summary = textwrap.fill(decoded_output, width=80).replace(\" .\", \".\")\n",
        "    print(formatted_summary)\n",
        "\n",
        "    print(\"\\nREFERENCE SUMMARY:\")\n",
        "    # Format the reference summary with line breaks every ~80 characters\n",
        "    formatted_reference = textwrap.fill(reference, width=80).replace(\" .\", \".\") + \".\"\n",
        "    print(formatted_reference)\n",
        "\n",
        "    print(\"\\n\" + \"-\" * 80 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfEP2rpwmdwF",
        "outputId": "906a553e-c689-4bba-8981-265f2fbed0a3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Article 1\n",
            "================================================================================\n",
            "\n",
            "GENERATED SUMMARY:\n",
            "Just four in 10 renters aged 20 to 45 are saving for a deposit to buy a home.\n",
            "Three-quarters of UK renters also fear they will never be able to afford to buy\n",
            "their own house. This rises to eight in 10 for Londoners, where house prices\n",
            "have risen by double-digits in recent years.\n",
            "\n",
            "REFERENCE SUMMARY:\n",
            "Just four in 10 renters aged 20 to 45 are saving for a deposit to buy a home.\n",
            "This is compared to almost half a year ago, according to Halifax research. Also\n",
            "found that three-quarters of UK renters fear they will never be able to afford\n",
            "to buy their own house..\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
